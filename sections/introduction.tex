
\section{Introduction}


\han{Only Fluency or Can be Proficiency? Verbal fluency might not be proper, it appears more in medical studies}

Spoken language fluency assessment~\cite{aldhanhani2020theories} is an essential task for educational AI, which helps language learners to improve their learning efficiency and experience. Until now, deep learning based assessment systems~\cite{metallinou2014using, cheng2015deep} were developed to achieve the state of the art performance. Typically, the assessment models are trained based on a large amount audio speech records with each record is labeled by human annotators to evaluate the speech's fluency. 


However, because of the large amount of training data to be labeled and the spoken language fluency is always subjective to the individual judgment of human annotators, there usually exists severe biases in the labeling process. For example, imagine that different annotators are assigned to score different divisions of speeches, their judgements can be fundamentally influenced by comparisons inside the assigned division, but
not reflect the overall fluency level in the whole population. In this way, the performance of fluency assessment models can be degraded.



In this work, we propose a novel framework to strengthen the ``objectivity'' of fluency labeling process. We aim to introduce auxiliary fluency scores which are annotated on the ASR outputted texts for the existing speeches. Intuitively, people's judgement on text fluency might have inherent different criterion with their judgements on speaking fluency. For example, \han{Some intuitive convincing reasons}. Thus, by including human's evaluation from diverse perspectives, we could effectively strengthen the ``objectivity'' in annotation. 

In this work we design a novel framework which can ....inspired by ESMM.


Moreover, we further improve performance of our fluency assessment models by jointly model the audio inputs and text inputs together. 

